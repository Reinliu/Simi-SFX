<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Simi-SFX</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Simi-SFX: A similarity-based conditioning method for controllable sound effects synthesis</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="/Users/reinliu/Downloads/Academic-project-page-template-master/index.html" target="_blank">Yunyi Liu</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?hl=en&user=BJ2HKOYAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Craig Jin</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Computing and Audio Research Laboratory, Department of Eletrical and Information Engineering<br>
                      The University of Sydney, Sydney, Australia</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="static/pdfs/AES.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/Reinliu/SCDDSP" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                  <!-- Colab link -->
                  <span class="link-block">
                    <a href="https://colab.research.google.com/drive/1gjLFRM8DzigBnoUKtBYDlp0wgi8Rk1oc?usp=sharing" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Colab</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2412.18710" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Similarity Score -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h2 class="subtitle has-text-centered">
        <div class="item">
          <!-- Your image here -->
          <img src="images/ICDDSP-Similarity.png" alt="MY ALT TEXT" style="margin-bottom: 50px;">
          <h2 class="subtitle has-text-centered">
            <p>
            Imagine a dataset with three categories of sounds, each with distinct timbre characteristics. We could use pre-trained audio representation
            models such as CLAP to extract the embeddings for each sound in our dataset. For any sound, we could also obtains for embedding and compare its
            similarity relative to each class by measuring its distance to the center of each embedding cluster. We take the idea from anomaly detection, 
            where we measure the Mahalanobis distance between the reference audio embedding and the embedding clusters of each class by treating each
            cluster as a Gaussian Distribution. The lower the distance, the more similar the sound is to that class. We could normalize the calculated 
            Mahalanobis Distance to range [0,1] and incorporate this similarity score as a conditioning information representing the timbre of the sound
            into the trianing process. 
            </p>
          </h2>
      </h2>
    </div>
  </div>
</section>
<!-- End Similarity Score -->


<!-- Architecture -->
<section class="hero is-small">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="title has-text-centered" style="margin-bottom: 50px;">Architecture</h1> <!-- Added margin-bottom style here -->
      <h2 class="subtitle has-text-centered">
        <img src="images/ICDDSP-Architecture.png" alt="MY ALT TEXT" style="margin-bottom: 30px;">
        <p>
          We could incorporate this similarity and condition it on a DDSP network. Loudness and spectral centroid envelopes are extracted from the 
          input audio and also passed as conditioning to the DDSP decoder. The decoder predicts corresponding parameters required for the transient
          and noise synthesizers to synthesize the waveform. 
        </p>
      </h2>
    </div>
  </div>
</section>
<!-- End Architecture -->





<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Regression analysis of the timbre control</h2>
      We plot the calculated Mahalanobis Distance between the generated sound and the reference sound by interpolating the input similarity score from
      0 to 1. The relationship between the normalized MD of each synthesized sound and its conditioning similarity score closely follows an exponential trend. 
      Ordinary Least Squares (OLS) regression yields a mean R^2 value of 0.4774 for the Footstep-set model and 0.6041 for the Impact-set model, indicating 
      a strong correlation between the conditioning similarity score c and the dependent variable y (Mahalanobis distance relative to each class).

      The plots reveal that almost all sound categories exhibit clear separations between the presence of a particular feature (at c = 0) and its absence 
      (at c = 1). This demonstrates that the model successfully learns to output distinct timbres based on the proposed similarity scores. Additionally, 
      the regression lines indicate a positive correlation between the normalized MD and the input similarity scores. This suggests that the conditioning 
      method effectively encodes timbral information unique to different sounds, independent of other acoustic features such as loudness and spectral centroid, 
      which were held constant during this test.
      <img src="images/Regression_analysis.png" alt="Regression Analysis of Timbre Control" style="width: 100%; max-width: 1400px; height: auto; margin-top: 20px;">
    </div>
  </div>
</section>
<!-- End paper poster -->



<div class="container">
  <!-- Central Title for all plots -->
  <h1 class="title has-text-centered" style="margin-top: 50px;">Creative usage of timbre control</h1>
  We qualitatively demonstrate how interpolating between two conditioning similarity scores produces distinct timbres. For this example, we randomly 
  selected a sound from our test dataset and extracted its loudness and spectral centroid as input. All channels of the similarity score were fixed at 1, 
  except for the first channel (C_1) and the second channel (C_2) which correspond to footsteps on metallic boards and footsteps on gravel, respectively. 
  These channels were interpolated from 0 to 1 (C_1) and 1 to 0 (C_2).

  The resulting spectrograms reveal a clear progression in timbre. Initially, the signals exhibit prominent harmonics in the higher frequencies, 
  characteristic of footsteps on metallic boards. As the interpolation progresses, these harmonics gradually transition into noisier signals lacking harmonic 
  structure, which are indicative of footsteps on gravel.
  <div class="container">
    <!-- Row 1 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=0.0, C2=1.0</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_0.png" alt="Plot 1">
                <audio controls>
                    <source src="Interpolate/C1_0.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  
    <!-- Row 2 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=0.2, C2=0.8</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_0.2.png" alt="Plot 2">
                <audio controls>
                    <source src="Interpolate/C1_0.2.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  </div>
  
  <div class="container">
    <!-- Row 1 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=0.4, C2=0.6</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_0.4.png" alt="Plot 1">
                <audio controls>
                    <source src="Interpolate/C1_0.4.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  
    <!-- Row 2 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=0.6, C2=0.4</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_0.6.png" alt="Plot 2">
                <audio controls>
                    <source src="Interpolate/C1_0.6.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  </div>
  
  <div class="container">
    <!-- Row 1 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=0.8, C2=0.2</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_0.8.png" alt="Plot 1">
                <audio controls>
                    <source src="Interpolate/C1_0.8.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  
    <!-- Row 2 -->
    <section class="section">
        <h2 class="title has-text-centered">C1=1.0, C2=0.0</h1>
        <div class="columns is-centered">
            <div class="column is-half has-text-centered">
                <img src="Interpolate/C1_1.0.png" alt="Plot 2">
                <audio controls>
                    <source src="Interpolate/C1_1.0.wav" type="audio/wav">
                    Your browser does not support the audio tag.
                </audio>
            </div>
        </div>
    </section>
  </div>

  <!-- More rows can be added below following the same structure -->
</div>

<!-- Example Sounds Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title has-text-centered">Example Outputs from Simi-SFX</h2>
    <p class="has-text-centered" style="margin-bottom: 30px;">
      The following examples showcase synthesized sound effects conditioned on different similarity scores. Each row corresponds to a specific reference category and displays four generated variants demonstrating timbral variation.
    </p>

    <!-- Sound Example Row -->
    <div class="columns is-multiline is-centered">
      <!-- Subtitle Column -->
      <div class="column is-2 has-text-centered">
        <h3 class="subtitle is-6">Footstep on Gravel</h3>
      </div>
      <!-- Sound 1 -->
      <div class="column is-2 has-text-centered">
        <audio controls>
          <source src="examples/gravel_1.wav" type="audio/wav">
          Your browser does not support the audio tag.
        </audio>
      </div>
      <!-- Sound 2 -->
      <div class="column is-2 has-text-centered">
        <audio controls>
          <source src="examples/gravel_2.wav" type="audio/wav">
          Your browser does not support the audio tag.
        </audio>
      </div>
      <!-- Sound 3 -->
      <div class="column is-2 has-text-centered">
        <audio controls>
          <source src="examples/gravel_3.wav" type="audio/wav">
          Your browser does not support the audio tag.
        </audio>
      </div>
      <!-- Sound 4 -->
      <div class="column is-2 has-text-centered">
        <audio controls>
          <source src="examples/gravel_4.wav" type="audio/wav">
          Your browser does not support the audio tag.
        </audio>
      </div>
    </div>

    <!-- Add more rows below as needed for different categories -->

  </div>
</section>
<!-- End Example Sounds Section -->




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{liu2024simisfxsimilaritybasedconditioningmethod,
        title={Simi-SFX: A similarity-based conditioning method for controllable sound effect synthesis}, 
        author={Yunyi Liu and Craig Jin},
        year={2024},
        eprint={2412.18710},
        archivePrefix={arXiv},
        primaryClass={cs.SD},
        url={https://arxiv.org/abs/2412.18710}, 
  }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>


  </body>
  </html>
